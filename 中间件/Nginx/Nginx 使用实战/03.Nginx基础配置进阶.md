# Nginx 基础配置进阶

[Nginx 指令索引表](http://nginx.org/en/docs/dirindex.html)包含了所有指令的使用语法，默认值和上下文环境。

## Context

指令支持的上下文环境。在使用指令前，需要明确其使用上下文，以期能得到预期效果。

## 获取请求 IP 地址

Nginx 内置变量 `$remote_addr` 可以获取到客户端的 IP 地址，但是在默认情况下该地址是经过 **中间代理（如CDN）** 处理后 IP 地址。在需要真实客户端 IP 地址进行日志记录，后端业务逻辑处理等场景中，使用 `$remote_addr` 获取 IP 地址可能会引入一些逻辑隐患。

```mermaid
graph LR
A[用户请求] --> B(CDN代理)
B --> C(Nginx)
C --> D[Web服务器]
```

### 获取请求的真实 IP 地址

如果要获取用户的真实 IP 地址，需要用到 realip 模块：

1. 在编译时指定 --with-http_realip_module 命令；

2. 并在 Nginx 的 http 块中配置如下代码：

   ```nginx
   set_real_ip_from xxx.xx.xx.xxx;  # 设置可信任的 IP 地址，即白名单，之后会使用 real_ip_header 从这些 IP 地址中获取请求头信息，如CDN_IP
   real_ip_header X-Forwarded-For;  # 从指定的请求头中获取客户端的IP地址，IP 地址是通过请求头传递给 Nginx 的，请求头可能包括多个IP地址（以逗号分隔），此时只会获取最左边的IP地址并赋值给 $remote_addr（客户端地址），此请求头一般会取值为 X-Forwarded-For；
   real_ip_recursive on;  # 如果设置为on，则表示启用递归搜索，会在real_ip_header指定的请求头信息中逐个匹配IP地址，最后一个不在白名单中的IP地址会被当作客户端地址。默认为off，表示禁用递归搜索，此时，只要匹配到白名单中的IP地址，就会把它作为客户端地址。
   ```

### 防止 IP 地址伪造

1. 如果没有使用 CDN，客户端的请求会直接和 Nginx 打交道。Nginx 可以使用自定义的请求头传递用户的IP地址，如 proxy_set_header X-Real-IP $remote_addr；

2. 如果使用了 CDN，可以和 CDN 提供商约定一个新的请求头，如 X-C-IP，在 CDN 代理客户请求时，要求CDN 使用该请求头传递用户的 IP 地址，并且在建立连接的过程中，通过 CDN 清除伪造的请求头，避免透传到后端。

   ```sequence
   客户端->CDN: 请求
   
   CDN->CDN: 获取客户端 IP 地址
   CDN->CDN: 存放到约定的秘密请求头 X-C-IP 中
   CDN->CDN: 保留服务器期望的请求头，剔除伪造的请求头
   
   CDN->Nginx: 发送请求
   
   Nginx->Nginx: set_real_ip_from CDN_IP;
   Nginx->Nginx: 使用 $http_x_c_ip 获取X-C-IP
   Nginx->Nginx: 使用自定义的请求头传递用户的 IP 地址
   Note right of Nginx: proxy_set_header X-Real-IP $http_x_c_ip;
   
   ```

   ### 后端服务器对 IP 地址的需求

   有时后端服务器也要用到用户的客户端 IP 地址，在这种情况下，研发团队需要在 IP 地址的获取上制定统一的规范，从规定的请求头信息中获取客户端 IP 地址。请求头中的 IP 地址可能有多个（经过了多次代理），它们以逗号分隔，其中第一个 IP 地址就是客户端 IP 地址。

## 管理请求的行为

可以通过配置 Nginx 访问限制来提高服务器安全性。

### 限制 IP 地址访问

| 指令  | 作用                                       | Context                           |
| ----- | ------------------------------------------ | --------------------------------- |
| allow | 允许 IP 地址或 IP 地址段访问，即访问白名单 | http,server,location,limit_except |
| deny  | 禁止 IP 地址或 IP 地址段访问               | http,server,location,limit_except |

allow/deny 指令在不同的指令块中配置有不同的效果：

-  http：允许/禁止所有 server_name 访问；
- server：允许/禁止某个 server_name 访问；
- location：允许/禁止对某个 location 访问。

```nginx
location / {
    deny 192.168.1.1;  # 禁止 192.168.1.1 访问
    allow 192.168.1.0/24;  # 允许 192.168.1.0/24 访问
    allow 17.1.1.2;  # 允许 17.1.1.2 访问
    deny all;  # 除 allow 的 IP 地址外，其他的 IP 地址都禁止访问
}
```

通过对访问的 IP 地址进行限制，可以阻挡可疑 IP 地址对服务的攻击，也可以确保内部接口只被内网访问。

### auth 身份验证

通过密码验证的方式对访问请求进行限制。

略。参考https://weread.qq.com/web/reader/a0a322707184550ba0adc41kb6d32b90216b6d767d2f0dc。

### 利用 LDAP 服务加强安全

auth_basic 使用统一的账号密码，无法对访问的用户进行区分。使用 LDAP 服务可以实现更为精确的账号管理接口。LDAP 最基础的功能就是让每个用户都使用自己的账号和密码。通过配置 LDAP 认证，可以提升 Nginx 权限配置的灵活性。

略。参考https://weread.qq.com/web/reader/a0a322707184550ba0adc41kb6d32b90216b6d767d2f0dc。

### satisfy 实现访问限制二选一功能

略。参考https://weread.qq.com/web/reader/a0a322707184550ba0adc41kb6d32b90216b6d767d2f0dc。

## proxy 代理

Nginx 使用 ngx_http_proxy_module 来完成对后端服务的代理。

### proxy_pass 请求代理规则

```wiki
Syntax:	proxy_pass URL;
Default:	—
Context:	location, if in location, limit_except
```

将请求代理到后端服务器，设置后端服务器的 IP 地址，端口号及 HTTP/HTTPS。

```nginx
# 将 URI 为 /test 的请求代理到 127.0.0.1 的 81 号端口上，使用 HTTP
location /test {
    proxy_pass http://127.0.0.1:81;
}

# 将 URI 为 /api/v1/xxx 的请求替换为 /xxx
location /api/v1/ {
    proxy_pass http://127.0.0.1:81/;
}

# 将 URI 为 /api/v1/xxx 的请求替换为 /test/xxx
location /api/v1/ {
    proxy_pass http://127.0.0.1:81/test/;
}
```

注：如果 location 块配置的 URI 使用了正则表达式，那么在使用 proxy_pass 时，就不能将 URI 配置到  proxy_pass 指定的后端服务器的最后面了，即禁止使用类似 `proxy_pass http://127.0.0.1:81/abc/`的方式，否则可能会导致一些不可预测的问题出现。

### 减少后端服务器的网络开销

有很多请求的内容只和 URL 有关，即后端服务器不需要读取请求体和请求头，只根据 URL 的信息即可生成所需的数据。在这种情况下，可以使用如下两个指令，并将其配置为 off，禁止传输请求体和请求头。

- proxy_pass_request_body：是否向后端服务器发送 HTTP 请求体，支持配置的环境有 http、server、location；
- proxy_pass_request_headers：是否向后端服务器发送 HTTP 请求头，支持的配置的环境有 http、server、location。

### 控制请求头和请求体

在请求被代理到后端服务器时，可以如下指令去控制请求头和请求体：

| 指令              | 作用                                                         | Context                |
| ----------------- | ------------------------------------------------------------ | ---------------------- |
| proxy_hide_header | 禁止某个请求头被转发到后端服务器，如禁止转发 Cache-Control 请求头，则用 proxy_hide_header Cache-Control，默认情况下，“Date”“Server”“X-Pad”“X-Accel-...”都不会被转发 | http, server, location |
| proxy_pass_header | 允许已被禁止转发的请求头继续转发                             | http, server, location |
| proxy_set_header  | 添加或修改请求头信息                                         | http, server, location |
| proxy_set_body    | 对请求体进行覆盖                                             | http, server, location |

在设置 proxy_set_header 后，下一层级会继承这个请求头的内容。但如果下一层级也配置了 proxy_set_header 指令，那么当请求到达下一层级时，在上一层级配置的请求头将会被全部清除。解决方法是在当前层级再显式设置上层配置的请求头。

### 控制请求和后端服务器的交互时间

控制请求和后端服务器交互时间的指令见下表：

| 指令                  | 作用                                                         | Context                |
| --------------------- | ------------------------------------------------------------ | ---------------------- |
| proxy_connect_timeout | 设置请求和后端服务器建立连接的超时时间，默认是60s            | http, server, location |
| proxy_read_timeout    | 设置后端服务器读取响应的超时时间，即两个相邻请求之间的时间，若在规定时间内客户端没有收到返回内容，就会关闭连接，默认是60s | http, server, location |
| proxy_send_timeout    | 设置请求发送到后端服务器的超时时间，即两个相邻请求之间的时间，如果在规定时间内后端服务器没有收到任何请求，就会关闭连接，默认是60s | http, server, location |

如果使用默认的设置，即60s，请求可能需要等待很久才会做出下一步反应，而客户端往往不会等待那么久，所以需要合理设置交互时间，并且最好能在超时后做一些合理的措施。如搭配使用 proxy_next_upstream* 命令。

## upstream 使用手册

```nginx
# 定义一个 HTTP 服务组
upstream test_servers {
    # 81 和 82 能够处理的请求数量比例为 2 : 1
    server 127.0.0.1:81 max_fails=5 fail_timeout=10s weight=10;
    server 127.0.0.1:82 max_fails=5 fail_timeout=10s weight=5;
    server test.123.com backup;  # 备用服务器
    server 127.0.0.1 down;
}

server {
    listen 80;
    location / {
        # 通过代理将请求发送给 upstream 命名的 HTTP 服务
        proxy_pass http://test_servers;
    }
}
```

可以使用 [ngx_http_upstream_module](http://nginx.org/en/docs/http/ngx_http_upstream_module.html) 将请求代理到多台服务器，提供负载均衡及故障转移等重要功能。

```wiki
Syntax:	upstream name { ... }
Default:	—
Context:	http
```

定义一组 HTTP 服务器，这些服务器可以监听不同的端口，TCP和UNIX套接字。在同一个 upstream 中可以混合使用不同的端口，TCP和 UNIX 套接字。

```wiki
Syntax:	server address [parameters];
Default:	—
Context:	upstream
```

配置后端服务器，参数可以时不同的 IP 地址，端口号甚至域名。server 可以设置如下参数：

| 参数         | 说明                                                         |
| ------------ | ------------------------------------------------------------ |
| weight       | 设置请求分发到后端服务器的权重，即每台后端服务器能够响应的请求数量的比例。如果设置相同的比例，意味着每台服务器能够响应的请求数量是一样的，默认是1。 |
| max_fails    | 在指定时间内请求失败的最大次数，默认为1。如果设置为0，则表示不检查失败次数。 |
| fail_timeout | 指定最大超时时间。如果在这个时间内失败次数超过了 max_fails 设置的值，则在接下来的 10s 内，此 server 不再接收任何请求， 10s 后重新恢复为可用，并重新计算失败次数。 |
| down         | 标记服务不可用。只有在使用 ip_hash 配置项时才有用。          |
| backup       | 当 upstream 中所有的后端服务器都为不可用时（如全都超过了请求最大失败次数），upstream 会启用标记为 backup 的服务器进行分流。在使用 ip_hash 配置项时该参数无效。 |

### 故障转移

如果 upstream 配置列表中出现了超过请求失败次数的服务器，可以使用以下参数对这些服务器进行配置。

#### proxy_next_upstream

```wiki
Syntax:	proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | non_idempotent | off ...;
Default: proxy_next_upstream error timeout;
Context: http, server, location
```

定义转发条件，当请求返回 Nginx 时，如果 HTTP 状态满足 proxy_next_upstream 设置的条件，就会触发 Nginx 将请求重新转发到下一台后端服务器，并累加出现此状态的服务器的失败次数（当超过 max_fails 和 fail_timeout的值时就会设置此服务器为不可用）。如果设置为 off，则表示关闭此功能。

#### proxy_next_upstream_tries

```wiki
Syntax:	proxy_next_upstream_tries number;
Default: proxy_next_upstream_tries 0;
Context: http, server, location
```

定义尝试请求的次数，达到次数上限后就停止转发，并将请求内容返回客户端。

#### proxy_next_upstream_timeout

```wiki
Syntax:	proxy_next_upstream_timeout time;
Default: proxy_next_upstream_timeout 0;
Context: http, server, location
```

限制尝试请求的超时时间。如果第一次请求失败，下一次请求就会被此参数值控制。若设置为 0，则表示无超时时间，但尝试的请求仍会受到 proxy_read_timeout、proxy_send_timeout、proxy_connect_timeout的影响。

通过这些配置，可以在后端服务器的某些节点出现请求异常时，快速做出故障切换的操作，从而屏蔽这些异常的请求。但是这存在一种隐患，即如果 proxy_next_upstream_tries 设置的值比较大，且 proxy_next_upstream 也设置了很多状态，当发生大面积异常时，重试不断累加，可能会导致请求反复向多个服务器发送，这样会给后端服务器带来更大的压力。

### 负载均衡

Nginx不仅支持代理多台后端服务器，也支持各种负载均衡模式，负载均衡在 upstream 的配置环境内设置（默认根据权重轮询）。

| 负载均衡指令                                                 | 说明                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [hash](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#hash) | Syntax: hash key [consistent]<br>Default: -<br>Context: upstream<br>按照指定的 key 将请求分布到后端服务器上，key 可以是变量，文本或它们的组合。<br>key相同的请求会被代理到同一台后端服务器上。<br>当从服务器组中增加/移除服务器时都会导致客户端和服务器之间重新建立映射关系。<br>如果指定了 consistent 参数，将使用 ketama 一致哈希方法。该方法确保在向组中添加服务器或从组中删除服务器时，只有少数客户端会和服务器之间重新建立映射关系。这样可以保证保存服务器获得更高的缓存命中率。 |
| [ip_hash](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#ip_hash) | 根据 IP 地址将请求分流到后端服务器上，同一个 IP 地址的请求会被代理到同一台后端服务器上，除非该服务器不可用。如需移除其中一台后端服务器，建议使用 down 对服务器设置停止分流，这样可以保留当前 IP 地址的 hash。原因同上。 |
| [least_conn](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#least_conn) | 当将请求进行分流时，请求量最小的服务器会优先获得分流，如果配置的服务器很多，会使用增加权重的 round-robin 负载方式。 |
| [sticky](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#sticky) | 根据 Cookie 将请求分布到后端服务器上，同一个 Cookie 的请求只会进入同一台服务器，如果请求被分布到某台服务器上，但是在请求时这台服务器已经无法提供服务，那么会重新选择一台服务器进行“捆绑”，并且下次会直接进入“捆绑”的服务器。 |

### 通过 hash 分片提高缓存命中率

缓存系统是减少后端服务压力的重要组件，常见的 HTTP 缓存系统有 Nginx 的 proxy_cache、varnish、squid。

如果通过反向代理去获取缓存数据，一般需要使用 hash 分片，以避免 URL 的请求随机进入缓存系统的某个分片，导致缓存命中率低、后端服务器压力上升。基于 URL 缓存的服务配置一般如下所示，相同的URL（包含参数）会进入相同的后端缓存系统。

```nginx
upstream test_servers {
    hash $request_uri;
    server 127.0.0.1:81 max_fails=5 fail_timeout=10s weight=10;
    server 127.0.0.1:82 max_fails=5 fail_timeout=10s weight=5;
}
```

- 增删节点会重新计算 hash，导致缓存失效，因此该操作尽量在服务低峰期进行；
- 在缓存系统上使用 max_fails 不一定是最好的选择，但一旦使用请确保 proxy_next_upstream 的合理性，尽量不要配置各种 HTTP 状态码，因为缓存系统代理的是后端服务，当后端服务异常时会将错误的状态码返回给 Nginx，这样会让 Nginx 以为缓存系统出了问题，从而将缓存节点当作失败的节点，停止分流。

缓存系统的故障转移应该只以**存活**检查方式（一般指检查缓存系统的端口是否存活，以及固定检查一个接口是否能返回正常的响应）为主。

### 利用长连接提升性能

在 Nginx 中，使用 upstream 进行后端访问默认用的是短连接，会增加网络资源的消耗。可以通过配置长连接，来减少因建立连接产生的开销、提升性能。

```nginx
keepalive_requests 1000; 
keepalive_timeout 60; 

upstream test_servers {
    hash $request_uri;
    server 127.0.0.1:81 max_fails=5 fail_timeout=10s weight=10;
    server 127.0.0.1:82 max_fails=5 fail_timeout=10s weight=5;
    
    keepalive 100; 
}

server {
    listen 80;
    
    proxy_set_header Host $Host;
    proxy_set_header x-forwarded-for $remote_addr;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_http_version 1.1;
    proxy_set_header Connection "";
    
    location / {
        # 通过代理将请求发送给 upstream 命名的 HTTP 服务
        proxy_pass http://test_servers;
    }
}
```

| 指令                                                         | 作用                                                         | Context  |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------- |
| [keepalive](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive) | 设置 worker 进程和后端服务器之间保持长连接的最大值           | upstream |
| [keepalive_requests](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive_requests) | 设置每个连接的最大请求次数，超过这个次数就会关闭该连接建立新的连接 | upstream |
| [keepalive_timeout](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive_timeout) | 设置 keep-alive 客户端连接在服务器端保持开启的超时时间       | upstream |
| proxy_http_version 1.1                                       | 设置 HTTP 请求协议，要确保时 HTTP 1.1 的长连接协议           |          |
| proxy_set_header Connection ""                               | 清空 Connection 请求头，避免客户端传递短连接的请求头信息     |          |
|                                                              |                                                              |          |

如果没有添加长连接，在压测环境中，可能会出现这样的情景：当压测达到一定的 QPS 后，Nginx 服务器突然“卡死”，QPS 直接降到几乎为0，但是压测并没有停，几分钟后又会自动恢复，然后再压测一段时间后，QPS又会突然降到接近于0，这种情况就要考虑是不是timewait的状态过多了。

### 利用 resolver 加速对内部域名的访问

proxy_pass 可以将域名代理到后端服务器上，请求前会县解析出 IP 地址。但是，返回的 DNS 会影响请求的速度，并且如果出现连接 DNS 服务器超时的情况，可能会导致请求无法发送，可以使用 DNS 缓存来解决这个问题。

```nginx
server {
    listen 80;
    
    location / {
        resolver 10.19.7.33 valid=30s;
        resolver_timeout 5s;
        set $upstream_host test2.com;
        # 通过代理将请求发送给 upstream 命名的 HTTP 服务
        proxy_pass http://$upstream_host:82;
    }
}
```

| 指令                                                         | 作用                                                         | Context  | 版本       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | -------- | ---------- |
| [resolver](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#resolver) | 配置用来解析后端服务器的 DNS 地址，如 10.19.7.33:5353，如果不配置端口，默认是53，参数 valid 用来设置 DNS 的缓存时间，当设置 resolver 指令是，在设定的缓存时间内不会触发 DNS 解析，而是使用之前的 IP 地址 | upstream | >=  1.17.5 |
| [resolver_timeout](http://nginx.org/en/docs/http/ngx_http_upstream_module.html#resolver_timeout) | 设置解析的超时时间，如果超过这个时间请求会报错               | upstream | >=  1.17.5 |

解析 DNS 后，通过 set $upstream_host test2.com 的方式，将获取的 IP 地址再赋值给 proxy_pass ，这是为了让 Nginx 重新去解析 DNS 中的IP地址。利用 valid 的配置，可以减少 DNS 的解析次数，从而提高请求的效率。当然对 DNS 缓存时间的控制也要有度，避免出现 DNS 切换 IP 地址后，Nginx 无法快速切换到新 IP 地址的情况。

## [rewrite 使用手册](https://weread.qq.com/web/reader/a0a322707184550ba0adc41k8e232ec02198e296a067180)

rewrite 是 ngx_http_rewrite_module 模块下的指令，用于完成重定向和跳转操作。

### 内部重定向

### 域名跳转

### 跳转 POST 请求

## [限速白名单](https://weread.qq.com/web/reader/a0a322707184550ba0adc41k4e73277021a4e732ced3b55)

Nginx 提供了ngx_http_limit_req_module 和 ngx_http_limit_conn_module 等模块来完成限制请求访问的功能，可以对请求的访问频率、User-Agent、带宽等各种条件进行限速。

## 日志

Nginx 通过 ngx_http_log_module 来对日志的记录进行配置。

---

Nginx 使用 log_format 指令配置日志的格式。

```wiki
Syntax:	log_format name [escape=default|json|none] string ...;
Default: log_format combined "...";
Context: http
```

### 记录自定义变量

```nginx
# 使用前需要初始化自定义变量
set $a 'a';
# 为自定义变量添加日志格式
log_format main '$remote_addr - $remote_user [$time_local] $a';
```

### 日志格式规范

日志经常会被用来分析和查找问题，为了提升日志的可读性，需要规范日志的格式以减少解析日志时出现的麻烦。

在 Nginx 1.11.8 版本之后，提供了 [escape=default|json|none] 配置，它可以让 Nginx 在记录变量时使用 JSON 格式或默认字符。如果使用默认字符则会被转义，特别是当 POST 请求中包含中文字符或需要转义的字符时，默认转义的操作会使日志无法记录明确的信息。

日志记录推荐使用如下格式：

```nginx
log_format json_log escape=json '{"ip": "$remote_addr", 
                          "timestamp": "$time_iso8601",'
                          "host": "$http_host",
                          "request": "$request",
                          "cookie": "$http_cookie",
                          "req_time": "$request_time",
                          "uri": "$uri",
                          "refer": "$http_refer" }';
```

使用 escape=json 则日志内容不会被转义，中文字符可以直接在日志里面显示。日志的格式采用 JSON 的方式进行配置，对后期的数据采集会有很大的帮助，当在日志里添加新的变量时，不会影响日志分析的流程。

### 日志存储

日志存储通过 access_log 来完成。

```wiki
Syntax:	access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];
                 access_log off;
Default: access_log logs/access.log combined;
Context: http, server, location, if in location, limit_except
```

- 在同一个阶段中，支持多种格式和文件的收集；若不在同一个阶段，则会以最小配置阶段的access_log为指定文件；
- 支持压缩存储，可以减少硬盘的使用空间；
- 支持只记录某些状态；
- 支持关闭日志记录。

## HTTP 执行阶段

HTTP执行阶段配置在 ngx_http_core_module 中，下载 Nginx 的源码包后在 src/http/ngx_http_core_module.h 中可以看到。Nginx 包含如下 11 个阶段（按照执行顺序排列）：

```c
typedef enum {
    // 读取并接收请求阶段
    NGX_HTTP_POST_READ_PHASE = 0,
    
    // 修改 URL 阶段，通常有重定向和变量设置的操作
    NGX_HTTP_SERVER_REWRITE_PHASE,

    // 查找 URL 对应的配置，如匹配 location
    NGX_HTTP_FIND_CONFIG_PHASE,
    // 在匹配到对应的 location 后，再次进入修改 URL 阶段
    NGX_HTTP_REWRITE_PHASE,
    // 检查 URL 是否执行过阶段4，如果执行过，就会重新执行阶段3，每个请求的最大检查次数是10，超过10次就会报错
    NGX_HTTP_POST_REWRITE_PHASE,

    // 一般用来在请求前设置对资源的控制，如限速
    NGX_HTTP_PREACCESS_PHASE,

    // 控制访问权限，例如限制某个 IP 地址的访问或外层代码的登录
    NGX_HTTP_ACCESS_PHASE,
    // 验证阶段7的权限控制结果
    NGX_HTTP_POST_ACCESS_PHASE,

    //  只有当使用 try_files 指令时才会生效
    NGX_HTTP_TRY_FILES_PHASE,

    // 处理 HTTP 请求内容的阶段，一般会和后端服务器进行交互
    NGX_HTTP_CONTENT_PHASE,

    // 日志记录阶段
    NGX_HTTP_LOG_PHASE
} ngx_http_phases;
```

